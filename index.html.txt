<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copy Text Buttons</title>
    <style>
        button {
            margin: 5px;
        }

        body {
            /* background-color: #1F1D36; */
            background-image: url("https://raw.githubusercontent.com/hel0118/sukuna/main/jujutsu-kaisen-sukuna-uhdpaper.com-4K-7.3063.jpg");
            background-size: 100% auto;
            /* Center the background image */
            font-family: Arial, sans-serif;
            text-align: center;
            transition: 1s ease-in-out;
        }

        @media only screen and (max-width: 600px) {

            /* Adjust properties for screens with a maximum width of 600px (adjust as needed) */
            body {
                background-image: url("https://raw.githubusercontent.com/hel0118/sukuna/main/real_esrgan_Zoro.jpg");
                background-size: 135%;
                /* Auto size for smaller screens */
                background-position: top;
                /* Center the background image, crop from top */
            }
        }


        button {
            color: #ccc;
            margin: 10px;
            padding: 10px;
            font-size: 16px;
            background-color: #dddddd00;
            /* Light gray button background */
            border: 1px solid #aaa;
            /* Dark gray border */
            cursor: pointer;
            transition: 500ms ease-in-out;
        }

        button:hover {
            color: darkslategrey;
            background-color: #ccc;
            /* Slightly darker background on hover */
        }
    </style>
</head>

<body>

    <button onclick="copyText(text1)">KNN 1A </button>
    <button onclick="copyText(text2)">K means clustering 1B</button>
    <button onclick="copyText(text3)">Bayesian network 2</button>
    <button onclick="copyText(text4)">polynomial regression (3) Overfitting</button>
    <button onclick="copyText(text5)">regression model (4)</button>
    <button onclick="copyText(text6)">Multiclass classification</button>
    <button onclick="copyText(text7)">K-Means</button>
    <button onclick="copyText(text8)">Decision Tree</button>
    <button onclick="copyText(text9)">Hierarchical Clustering</button>
    <p id="copiedMsg"></p>
    <script>
        var text1 = `
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score,classification_report,precision_score

Iris = load_iris()
X,Y =  Iris.data ,Iris.target
X_train,X_test , Y_train , Y_test  = train_test_split(X,Y,test_size=0.3)

KNeighbors_Classifier = KNeighborsClassifier(n_neighbors=3)

#Train  the model under training data
KNeighbors_Classifier.fit(X_train,Y_train)
#Make prediction on a test data
Y_pred =  KNeighbors_Classifier.predict(X_test)
#Evaluate the model accuracy
accuracy =  accuracy_score(Y_test,Y_pred)
print(accuracy)
`;

        var text2 = `
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

Iris = load_iris()
X,Y =  Iris.data ,Iris.target
X_train,X_test , Y_train , Y_test  = train_test_split(X,Y,test_size=0.3)

Kmeans=  KMeans(n_clusters=3,random_state=42)
Kmeans.fit(X)

cluster_label = Kmeans.labels_

plt.scatter(X[:,0],X[:,1],c=cluster_label,cmap='viridis')
plt.xlabel("Sepal Length")
plt.ylabel("Sepal widht")
plt.show()
`;
        var text3 = `
!pip install pgmpy

import pandas as pd
from pgmpy.estimators import MaximumLikelihoodEstimator
from pgmpy.models import BayesianModel
from pgmpy.inference import VariableElimination

data = pd.read_csv("ds4.csv")
heart_disease = pd.DataFrame(data)
print(heart_disease)
model = BayesianModel([
    ('age', 'Lifestyle'),
    ('Gender', 'Lifestyle'),
    ('Family', 'heartdisease'),
    ('diet', 'cholestrol'),
    ('Lifestyle', 'diet'),
    ('cholestrol', 'heartdisease'),
    ('diet', 'cholestrol')
])
print("Aseer Momin KFMSCIT023")
model.fit(heart_disease, estimator=MaximumLikelihoodEstimator)

HeartDisease_infer = VariableElimination(model)

print('For Age enter SuperSeniorCitizen:0, SeniorCitizen:1, MiddleAged:2, Youth:3, Teen:4')
print('For Gender enter Male:0, Female:1')
print('For Family History enter Yes:1, No:0')
print('For Diet enter High:0, Medium:1')
print('for LifeStyle enter Athlete:0, Active:1, Moderate:2, Sedentary:3')
print('for Cholesterol enter High:0, BorderLine:1, Normal:2')
print("Aseer Momin KFMSCIT023")
q = HeartDisease_infer.query(variables=['heartdisease'], 
    evidence={
    'age': int(input('Enter Age: ')),
    'Gender': int(input('Enter Gender: ')),
    'Family': int(input('Enter Family History: ')),
    'diet': int(input('Enter Diet: ')),
    'Lifestyle': int(input('Enter Lifestyle: ')),
    'cholestrol': int(input('Enter Cholestrol: '))
})

print(q)
`;

        var text4 = `
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generate synthetic data
np.random.seed(0)
X = np.linspace(0, 5, 100).reshape(-1, 1)
Y = 2 * np.sin(X) + np.random.normal(0, 0.5, size=X.shape)

# Split data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Define a function to fit polynomial regression models of varying degrees
def fit_polynomial(X_train, Y_train, X_test, Y_test, degree):
    poly = PolynomialFeatures(degree=degree)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)

    model = LinearRegression()
    model.fit(X_train_poly, Y_train)

    train_rmse = np.sqrt(mean_squared_error(Y_train, model.predict(X_train_poly)))
    test_rmse = np.sqrt(mean_squared_error(Y_test, model.predict(X_test_poly)))

    return model, train_rmse, test_rmse

# Fit polynomial regression models of varying degrees
degrees = [1, 3, 10]
models = []
train_rmse_values = []
test_rmse_values = []

for degree in degrees:
    model, train_rmse, test_rmse = fit_polynomial(X_train, Y_train, X_test, Y_test, degree)
    models.append(model)
    train_rmse_values.append(train_rmse)
    test_rmse_values.append(test_rmse)

# Plot the results
plt.figure(figsize=(10, 6))
plt.scatter(X_train, Y_train, color='blue', label='Training Data')
plt.scatter(X_test, Y_test, color='green', label='Testing Data')

x_values = np.linspace(0, 5, 100).reshape(-1, 1)
for i, model in enumerate(models):
    y_values = model.predict(PolynomialFeatures(degree=degrees[i]).fit_transform(x_values))
    plt.plot(x_values, y_values, label=f'Degree {degrees[i]}')

print("Aseer Momin KFMSCIT023")
plt.title('Polynomial Regression with Different Degrees')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.show()
`;

        var text5 = `
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,r2_score

df = pd.read_csv("D:\MSC IT KC\SEM 2\ML\Practicals\Salary_Data.csv")
df.head()

x=df['YearsExperience'].values.reshape(-1,1)
y=df['Salary'].values

X_train,X_test , Y_train , Y_test  = train_test_split(x,y,test_size=0.2)

r1 = LinearRegression()
r1.fit(X_train,Y_train)
y_pred = r1.predict(X_test)
print(y_pred)

MSE = mean_squared_error(Y_test,y_pred)
r2 = r2_score(Y_test,y_pred)
print('MSE',MSE)
print('r2' , r2)

plt.scatter(X_test,Y_test,color='blue',label='Actual')
plt.plot(X_test,y_pred,color='red',label='Predict')
plt.xlabel('year od experience')
plt.ylabel('salary')
plt.legend()
plt.show()
`;

        var text6 = `
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score

# step 1 : load the iris dataset

iris = load_iris()
x = iris.data
y = iris.target

xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2)

from sklearn.svm import SVC
model = SVC()
model.fit(xtrain,ytrain)
modelPredict = model.predict(xtest)

aS = accuracy_score(modelPredict,ytest)
f1 = f1_score(modelPredict,ytest,average='macro')
rs = recall_score(modelPredict,ytest,average='macro')
ps = precision_score(modelPredict,ytest,average='macro')

print("Aseer Momin KFMSCIT023")
print("accuracy_score: ",aS)
print("recall_score: ",rs)
print("precision_score: ",ps)
print("f1_score: ",f1)
`;

        var text7 = `
import numpy as np

# sample data representating flower location
data = np.array([[1,2],[1.5,1.8],[5,8],[8,8],[1,0.5],[7,9],[9,10],[5.5,8.5]])

# define the number of cluster
k = 3

# impementing algo
from sklearn.cluster import KMeans
kmean = KMeans(n_clusters=k)

# Traning algo
kmean.fit(data)
cluster_label = kmean.predict(data)
print("Aseer Momin KFMSCIT023")
# ploting
import matplotlib.pyplot as plt
plt.scatter(data[:,0],data[:,1],c=cluster_label)
plt.xlabel('X Co-ordinates')
plt.ylabel('Y Co-ordinates')
plt.title('K Mean Clustering (K = '+str(k)+")")
plt.show()
`;

        var text8 = `
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

print("Aseer Momin KFMSCIT023")

data = pd.read_csv(r'C:\Users\hp\Desktop\KC MScIT Part 1\Sem 1\AAI\Practical\iris.csv')
print(data.head())

X = data.drop('variety', axis=1)
y = data['variety']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = DecisionTreeClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, feature_names=X.columns.tolist(), class_names=y.unique().tolist())
plt.title("Decision Tree Visualization")
plt.show()
`;

        var text9 = `
import numpy as np
from sklearn.cluster import AgglomerativeClustering # this clustering is used for hirerchical clustering
from sklearn.metrics import completeness_score, silhouette_score

data = np.array([[1,1],[5,5],[8,8],[1,0],[5,4],[8,1]])
print("Aseer Momin KFMSCIT023")
linkage = 'ward'
model = AgglomerativeClustering(linkage=linkage,n_clusters=3)
model.fit(data)
cluster_label = model.labels_
s = silhouette_score(data,cluster_label) #positive is good and negative value is bad 
print("silhouette_score: ",s)
g = None
if linkage == 'ward' and g != None:
    c = completeness_score(g,cluster_label)
    print("completeness_score: ",c)
else:
    print("Not aplicable...")`;
        function copyText(text) {
            navigator.clipboard.writeText(text).then(function () {
                document.getElementById('copiedMsg').innerHTML = "Text Copied"
            }).catch(function (err) {
                console.error('Unable to copy text', err);
            });
        }
    </script>

</body>

</html>